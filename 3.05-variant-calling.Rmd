# Variant calling

Using aligned sequencing data to identify positions in the genome at which
polymorphism is segregating in your sample---and identifying the genotypes
of your sampled individuals at each of those variable positions---is a crucial
step in conservation genomics.  This is the step where sequence data are finally
converted into genotypes for individuals, and it is information about these
genotypes that will get used in downstream analyses to answer the questions
that you actually want to answer as a conservation geneticist: How much 
genetic variation remains in this small population? What does the population
structure of this species look like across North America? Can I find evidence
that this animal is using migratory corridors through wetlands? Is this rare
species at risk due to hybridization with a more abundant introduced species? etc.
All of these questions make use of variant data, because there is not much to
be gleaned by looking only at portions of the genome that are identical between
all individuals.  

At the same time, this variant-calling and genotyping step is the place
in the next-generation sequencing bioinformatic workflow when you will be
most aggressively confronted with issues of statistical inference.  It becomes
important to have at least a rudimentary understanding of the process of
inference and the difference between likelihoods and posterior probabilities,
so we will touch on such themes in this chapter.

We start with a sketch of the models used to compute _genotype likelihoods_
and describe what those quantities are.  All of the models in use derive
from a simple conceptual model in which we are trying to learn about the sequence
at a genomic position on the two homologous chromosomes within a diploid
individual by drawing samples from them---those samples are the sequencing reads.
We then proceed to three different programs/workflows that compute such genotype
likelihoods: two of them---`angsd` and `bcftools mpileup` operate directly on the
aligned positions in BAM files, while the third, `GATK HaplotypeCaller` takes the
aligned reads in a BAM as a starting point to do another round of local realignment/assembly
of the reads.

After discussion of these methods for calculating _genotype likelihoods_ we
will consider some of the sources of uncertainty/variability in their calculation.
One of the main themes is their rather strong dependence on the estimated base quality
scores, and we will touch briefly upon the idea of _base quality score recalibration_.

Finally, we will consider the issue that many procedures in which we would like to
use our data require _genotypes_ as input, rather than _genotype likelihoods_.  As a
consequence, we can either convert our genotype likelihoods into called genotypes, or
we can make use of methods that can take genotype likelihoods as input.  The former can
be problematic because it does not allow uncertainty about the genotyeps to be propagated
to the result, and can lead to systematic biases in genotype data sets. We will look at
some of that from early RAD sequencing data.  For many analyses, however, a version
that relies on genotype likelihoods rather than genotypes might not be available.


## Genotype Likelihoods

### Basic Sketch of Genotype Likelihood Calculations

There are several genotype likelihood models in use, but they all
share a number of properties and assumptions.  Perhaps the easiest
way to come to understand how genotype likelihoods are calculated is
to work through a simple example, like that show in Figure \@ref(fig:genolike).
```{r genolike, echo=FALSE, fig.align='center', dpi=80, fig.cap='An example scenario for genotype likleihood calculation'}
knitr::include_graphics("figs/genotypes_and_reads.svg", auto_pdf = TRUE)
```
The figure shows a situation where we know that there is variation (a SNP that
has two possible alleles: T anc C) at a certain
position along a given chromosome.  A diploid individual is represented by the two homologous
chromosomes that s/he carries, and the alleles carried on those chromosomes are represented
by `?`'s because we don't know (without collecting and analyzing data) what the genotype
of that individual is.

The _data_ that we will use to determine the genotype of this individual are the
4 reads from the individual that cover the position we are interested in. Specifically,
from each read we observe:

- The reported base at the position
- The reported _base quality score_ at the position.  Recall from Section \@ref(bqscores) that the
Phred-scaled base quality score is interpreted as $\lfloor -10\log_{10}\epsilon\rfloor$, where $\epsilon$ is the
estimated probability that the reported base at the position is incorrect.  

We can condense the data down to the base calls, $B$, and $\epsilon$'s at each of the four reads. To do
so we convert the Phred score $Q$ to $\epsilon$ using $\epsilon = 10^{-Q/10}$

1. $B_1 = C$ and $\epsilon_1 = 10^{-32/10} = 0.00063$
1. $B_2 = C$ and $\epsilon_2 = 10^{-37/10} = 0.00019$
1. $B_3 = T$ and $\epsilon_3 = 10^{-35/10} = 0.00031$
1. $B_4 = C$ and $\epsilon_4 = 10^{-33/10} = 0.00050$

Those are the raw data that go into our calculations of how likely it is that the
true genotype of the individual is either a homozygote, $CC$, or a homozygote, $TT$,
or a heterozyote, $CT$ or $TC$ (referred to simply as $CT$ from now on).

There are a few
different ways that one might go about this task. One of the simplest would be
the "method of the eyeball," by which you would just look at the reads and
say, "That individual is probably a heterozygote, $CT$."  This is actually
a reasonable assessment in this situation; however it is not highly principled
and it is hard to instruct a computer to employ the "method of the eyeball."

By contrast, the _method of likelihood_ provides a principled approach to
evaluating how much evidence a _given set of data_, $D$, provides to distinguish between
several different hypotheses. In our case, the three different hypotheses are that
the true, underlying genotype, $G$ is either $CC$, $CT$, or $TT$.  It is also relatively
easy to tell a computer how to compute it.  

Let's be explicit agout our terms.  We have three different hypotheses:

- $H_1:~~~G = CC$
- $H_2:~~~G = CT$
- $H_3:~~~G = TT$

In our situation, as we have defined it, those are the three possibilities.  And we want to
calculate the evidence in our data $D$ (which in this case is $B_i$ and $\epsilon_i$, for
$i = 1,2,3,4$) in support
of those different hypotheses.

The method of likelihood states that the evidence in the data $D$ supporting a hypothesis
$H_i$, can be quantified as being proportional to the probability of the data given the
hypothesis.  Hence we write:
$$
L(H_i~|~D) \propto P(D~|~H)
$$
Thus, to compute $L(H_1~|~D) = L(G = CC~|~D)$ we must calculate the probability of observing
the four reads, C, C, T, C, given that the true, underlying genotype is $CC$.  To do so
requires a conceptual model of how reads arrive to us from the different chromosomes in an
organism. Forming such a model requires that we make some assumption.
Two assumptions that are shared by most genotyping likelihood models are:

1. Reads are sampled independently from the two homologous chromosomes in an
individual, each with probability $1/2$.
2. Given the true sequence on the chromosome from which the read is a sample, the base at each 
position is recorded as the true base on the chromosome with probability $1 - \epsilon$, and,
with probability $\epsilon$ the base is recorded incorrectly.

With these two assumptions, it is straightforward to calculate the probability of the
observed base on a single read given each of the three different possible true genotypes.
Let's do that with the first read, which has $B_1 = C$ and $\epsilon_1 = 0.00063$,for the three
different possible true genotypes:

- If $G=CC$ then, with probability $1/2$ the read is from the first chromosome or with probability $1/2$
the read is from the second chromosome; however, in either case that read is from a chromosome that
carries a $C$.  So with probability 1 the read is from a chromosome with a $C$. Hence with probability
$1-\epsilon_1$ the read carries a $C$.  So, 
$$
P(B_1=C~|~G=CC, \epsilon_1) = 1 - \epsilon_1
$$
- If $G=CT$ then, with probability $1/2$, the read is from the chromosome with a $C$, in which case
the probability of observing a $C$ on the read is $1 - \epsilon$.  On the other hand, with probability
$1/2$ the read is from the chromosome carrying a $T$, in which case, recording a $C$ requires that
a sequencing error occurred.  Therefore:
$$
P(B_1=C~|~G=CT, \epsilon_1) = \frac{1}{2}(1 - \epsilon) + \frac{1}{2}\epsilon_1
$$
Notice that this is less than $P(B_1=C~|~G=CC, \epsilon_1)$ by a factor of about 2.
- Finally, if $G=TT$, then, with probability 1, the read will come from a chromosome
carrying a $T$, and in that case, the only way that we could have recorded a $C$ from
the read would be if a sequencing error occurred.  Hence:
$$
P(B_1=C~|~G=TT, \epsilon_1) = \epsilon_1
$$
So, summarizing the information from the first read we have:
$$
\begin{align*} 
L(G=CC | B_1 = C) &=   P(B_1 = C| G=CC, \epsilon_1) &  &=  1 - \epsilon_1 & &= 0.99937 \\ 
L(G=CT | B_1 = C) &=   P(B_1 = C| G=CT, \epsilon_1) & &=  \frac{1}{2}(1 - \epsilon_1) + \frac{1}{2}\epsilon_1 & &= 0.5 \\ 
L(G=TT | B_1 = C) &=   P(B_1 = C| G=TT, \epsilon_1) & &=  \epsilon_1 & &= 0.00063
\end{align*}
$$
A higher likelihood implies more support for a hypothesis. So, with that one
read we have good evidence that the true genotype is not $G=TT$, and twice
the likelihood that $G=CC$ compared to $G=CT$.


Now, more quickly, we can consider how much evidence **read 3**, $B_3 = T$ with $\epsilon_3 = 0.00031$ offers:
$$
\begin{align*} 
L(G=CC | B_3 = T) &=   P(B_3 = T| G=CC, \epsilon_3) &  &=   & \epsilon_3 &= 0.00031 \\ 
L(G=CT | B_3 = T) &=   P(B_3 = T| G=CT, \epsilon_3) & &=  \frac{1}{2}(1 - \epsilon_3) + \frac{1}{2}\epsilon_3 & &= 0.5 \\ 
L(G=TT | B_3 = T) &=   P(B_3 = T| G=TT, \epsilon_3) & &=  1 - \epsilon_3 & &= 0.99969
\end{align*}
$$
OK, that tells us there is very little support for $G=CC$, and twice as much support for $G=TT$ as
there is for $G=CT$.  

How do we combine the likelihoods from the different reads? Well, we compute the probability of observing
both of those reads.  Since we assumed that reads are sampled independently from the pair of homologous
chromosomes, the joint probability of both reads is merely the product of probabilities for each read.
So, we have:
$$
\begin{align*} 
L(G=CC | B_1 = C, B_3 = T) &=   P(B_1 = C| G=CC, \epsilon_1) \times P(B_3 = T| G=CC, \epsilon_3) & &= 0.99937 * 0.00031  & &= 0.00031\\ 
L(G=CT | B_1 = C, B_3 = T) &=   P(B_1 = C| G=CT, \epsilon_1) \times P(B_3 = T| G=CT, \epsilon_3) & &=  0.5 * 0.5 & &= 0.25\\ 
L(G=TT | B_1 = C, B_3 = T) &=  P(B_1 = C| G=CT, \epsilon_1) \times P(B_3 = T| G=TT, \epsilon_3) & &=  0.00063 * 0.99969 & &= 0.00063
\end{align*}
$$
So, with only two reads, one of each allele, the likelihood of a heterozygote can be quite high.

Adding the data from the two remaining reads does not change the likelihood much, apart from 
factors of 1/2 on the heterozygote category.

What have we learned from this exercise?  I'd say there are two very important take-home messages:

1. If you have only a single read, the likelihood that the genotype is a homozygote is always higher than
the likelihood that it is a heterozygote.
1. If you only see reads of a single allele, the likelihood that the genotype is a heterozygote
drops by a factor of two for each new read.
2. The values of the likelihoods for the homozygous hypotheses are highly dependent on the base quality scores but not so much for the likelihood of the heterozygous hypothesis.


Before we leave this section, we want to stress to the reader that genotype likelihoods are
only half of the equation when it comes to determining what an individuals genotype is. We will
talk about that more in the section on posterior probabilities. Suffice it to say, at this
point, that assigning genotypes according to the maximum likelihood (which is common in programs
like GATK) is a terrible idea with low read-depth data, because individuals that are truly
heterozygotes will never be called as heterozygotes, unless both alleles have been observed
in the read data.




### Specifics of different genotype likelihoods

Will (eventually) write out the exact details of samtools's old and GATK old likelihoods.  Also bcftools new likelihood
and SOAP.

### Computing genotype likelihoods with three different softwares

At this juncture we will spend a little time looking at the genotype likelihoods computed
by some programs.  

#### GATK

We did this last week in Section \@ref(install-gatk).  Here are the first few variants.
```
CM009233.1      2000947 .       C       T       42.21   .       AC=2;AF=0.167;AN=12;BaseQRankSum=-1.085;DP=12;ExcessHet=0.202;FS=0;MLEAC=3;MLEAF=0.25;MQ=59.6;MQRankSum=0.282;QD=21.1;ReadPosRankSum=0.812;SOR=0.223    GT:AD:DP:GQ:PL  0/0:1,0:1:3:0,3,42      0/0:2,0:2:6:0,6,66      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,2:2:6:49,6,0      0/0:1,0:1:3:0,3,32      0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     0/0:2,0:2:6:0,6,49      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2000978 .       CACAAAGGTTGTTGACA       C       579.31  .       AC=16;AF=1;AN=16;DP=13;ExcessHet=3.0103;FS=0;MLEAC=20;MLEAF=1;MQ=59.63;QD=25.36;SOR=1.445       GT:AD:DP:GQ:PL  1/1:0,1:1:3:45,3,0      1/1:0,3:3:9:135,9,0     1/1:0,1:1:3:34,3,0      ./.:.:.:.:.     1/1:0,1:1:3:34,3,0      ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      1/1:0,1:1:3:45,3,0      1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001030 .       C       A       39.05   .       AC=2;AF=0.111;AN=18;BaseQRankSum=-0.988;DP=13;ExcessHet=0.1296;FS=0;MLEAC=2;MLEAF=0.111;MQ=59.63;MQRankSum=0.64;QD=19.52;ReadPosRankSum=-0.395;SOR=0.33 GT:AD:DP:GQ:PL  0/0:1,0:1:3:0,3,10      0/0:3,0:3:9:0,9,94      0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     ./.:.:.:.:.     0/0:2,0:2:6:0,6,49      0/0:1,0:1:3:0,3,45      0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     1/1:0,2:2:6:49,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001031 .       A       C       525.77  .       AC=18;AF=1;AN=18;DP=13;ExcessHet=3.0103;FS=0;MLEAC=21;MLEAF=1;MQ=59.63;QD=28.73;SOR=1.179       GT:AD:DP:GQ:PL  1/1:0,1:1:3:10,3,0      1/1:0,3:3:9:94,9,0      1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,2:2:6:49,6,0      1/1:0,1:1:3:45,3,0      1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,1:1:3:37,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001120 .       A       G       341.62  .       AC=10;AF=1;AN=10;DP=19;ExcessHet=3.0103;FS=0;MLEAC=15;MLEAF=1;MQ=59.75;QD=30.97;SOR=1.863       GT:AD:DP:GQ:PL  1/1:0,1:1:3:35,3,0      ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001129 .       A       AT      341.52  .       AC=10;AF=1;AN=10;DP=19;ExcessHet=3.0103;FS=0;MLEAC=15;MLEAF=1;MQ=59.75;QD=27.24;SOR=1.863       GT:AD:DP:GQ:PL  1/1:0,1:1:3:35,3,0      ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001144 .       TG      T       388.99  .       AC=12;AF=1;AN=12;DP=15;ExcessHet=3.0103;FS=0;MLEAC=17;MLEAF=1;MQ=59.68;QD=28.2;SOR=1.863        GT:AD:DP:GQ:PL  1/1:0,1:1:3:35,3,0      1/1:0,1:1:3:40,3,0      1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001489 .       G       A       279.02  .       AC=6;AF=0.429;AN=14;BaseQRankSum=0.384;DP=22;ExcessHet=0.7136;FS=2.463;MLEAC=10;MLEAF=0.714;MQ=60;MQRankSum=0;QD=25;ReadPosRankSum=0.563;SOR=0.693      GT:AD:DP:GQ:PL  ./.:.:.:.:.     0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     ./.:.:.:.:.     0/0:1,0:1:3:0,3,45      ./.:.:.:.:.     ./.:.:.:.:.     0/0:3,0:3:9:0,9,94      1/1:0,5:5:15:153,15,0   0/1:1,1:2:39:39,0,39    ./.:.:.:.:.     0/1:2,1:3:36:36,0,40    ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2001671 .       C       A       520.16  .       AC=9;AF=0.9;AN=10;BaseQRankSum=-0.115;DP=28;ExcessHet=3.0103;FS=4.472;MLEAC=16;MLEAF=1;MQ=60;MQRankSum=0;QD=32.51;ReadPosRankSum=0.109;SOR=1.284        GT:AD:DP:GQ:PL  ./.:.:.:.:.     1/1:0,3:3:9:59,9,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,3:3:9:94,9,0      ./.:.:.:.:.     1/1:0,3:3:9:117,9,0     ./.:.:.:.:.     ./.:.:.:.:.     0/1:1,4:5:27:124,0,27   ./.:.:.:.:.     1/1:0,2:2:6:87,6,0      ./.:.:.:.:.     ./.:.:.:.:.
CM009233.1      2002006 .       C       CTCAAGAGCAT     502.77  .       AC=14;AF=1;AN=14;DP=18;ExcessHet=3.0103;FS=0;MLEAC=19;MLEAF=1;MQ=55.82;QD=29.56;SOR=2.303       GT:AD:DP:GQ:PL  1/1:0,1:1:3:45,3,0      1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,1:1:3:45,3,0      1/1:0,1:1:3:45,3,0      1/1:0,3:3:9:135,9,0     1/1:0,1:1:3:45,3,0      ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     ./.:.:.:.:.     1/1:0,2:2:6:90,6,0      ./.:.:.:.:.     ./.:.:.:.:.
```

**EXERCISE**:

Look at the FORMAT/PL field in the genotype columns.  Those are the "Phred-scaled genotype likelihoods".
Compute what those are in terms of likelihoods (not Phred scaled) and see how they compare to what you
see in the allele-specific read depths: (FORMAT/AD field).  Here are some examples from the file
to work through:
```
GT:AD:DP:GQ:PL  0/0:1,0:1:3:0,3,42
GT:AD:DP:GQ:PL  0/1:1,1:2:39:39,0,39
GT:AD:DP:GQ:PL  1/1:0,3:3:9:135,9,0
```

Look at those numbers and think about it and then tell me which of the three errors
you think will be more common:

- Mistakenly calling a true AC heterozygote as a CC homozygote
- Mistakenly calling a true AA homozygote as a CC homozygote
- Mistakenly calling a true AA homozygote as an AC heterozygote




#### `bcftools mpileup`

Now, for fun, we can compute genotype likelihoods using the `bcftools mpileup` subcommand.
The `mpileup` functionality used to be packaged up in the `samtools` utility, but was moved
into `bcftools`.

The syntax for using it in this context, to compute genotype likelihoods in a 
20 Kb section of the genome we have mapped is as follows---being sure that you are in the
`chr-32-bioinformatics-username` directory:
```sh
# be sure that you are on a compute node

# activate your conda environment that has bcftools
conda activate bioinf

# do the call.  By default, it outputs in VCF format. Add the AD and DP FORMAT tags
bcftools mpileup \
  -f genome/GCA_002872995.1_Otsh_v1.0_genomic.fna \
  -r CM009233.1:2000000-2020000 \
  -a AD,DP \
  mkdup/*.bam > vcf/geno-likes-from-bcftools.vcf
  
# after that is done, look at the names of the individuals
bcftools query -l vcf/geno-likes-from-bcftools.vcf

# also check the types of the INFO and FORMAT fields:
bcftools view -h vcf/geno-likes-from-bcftools.vcf  | awk '/INFO/ || /FORMAT/'

# What is the FORMAT field there?

# Now, look at the first 10 positions:
bcftools view  vcf/geno-likes-from-bcftools.vcf | awk '/^##/ {next} /^#CHROM/ {print; next} {print}' | head

# How many rows are in this file?
bcftools view -H  vcf/geno-likes-from-bcftools.vcf | wc
```
Check that out! It has computed values for almost every single base pair in the 20,000 KB
genomic region.

To turn that mpileup VCF into something that has information on variable positions,
you can  "call" genotypes, using `bcftools call`.  The `-v` option says "keep only
the variable sites", and the `-m` says "use the genotype caller that can deal
with multiallelic sites."
```sh
bcftools call -v -m vcf/geno-likes-from-bcftools.vcf > vcf/geno-calls-from-bcftools.vcf

# now look at what we have
bctools view -h vcf/geno-calls-from-bcftools.vcf | head 
```
Compare those to the variants found by GATK (listed above)


#### `angsd`

We will do this later.

### A Directed Acyclic Graph For Genotype Likelihoods

The assumptions about independence between reads and the formulation of the
genotype likelihood model can be captured in an _acyclic directed graph_ (called a DAG, for short) like
that in Figure \@ref(fig:single-geno-like-dag).  We expand the notation established above,
but subscript each variable by an additional $i$ to indicate the data are from the $i$-th individual,
and, rather than referring to the genotype as $G$ we specifically indicate the allelic type of
each gene copy within individual $i$ with the variable $Y$.  
Thus, $B_{i,1}$ is the base covering the SNP at the first read from indivdiual $i$,  $\epsilon_{i,1}$ is the
base quality score (as a probability of a sequencing error) at that SNP on the first read from
individual $i$, and $Y_{i,1} = C$ and $Y_{i,2} = T$ denote that the genotype of individual
$i$ is heterozygous, $CT$.
```{r single-geno-like-dag, echo=FALSE, fig.align='center', dpi=80, fig.cap='A simple DAG expressing the genotype likelihood for a single read'}
knitr::include_graphics("figs/single-geno-like.svg", auto_pdf = TRUE)
```

Of course, we may will typically have sequencing data from multiple individuals. So let us imagine
that we have data from $N$ individuals ($i=1,\ldots, N$).  Additionally, each individual will have a
variable number of reads covering the SNP we are focused on.  We denote that number of reads by
$R_i$ for the $i$-th individual, and subscript each read by $j$.  Hence, in the $i$-th individual,
$j=1,\ldots,R_i$.  Then, our DAG can be expanded to what we find in Figure \@ref(fig:plated-single-geno-like).
```{r plated-single-geno-like, echo=FALSE, fig.align='center', dpi=80, fig.cap='An expanded DAG showing replication over individuals, and over reads within individuals.'}
knitr::include_graphics("figs/plated-single-geno-like.svg", auto_pdf = TRUE)
```

Acyclic directed graphs can be very useful for gleaning the underlying structure of statistical models
and also for developing intuition for what is involved in the process of _inference_.

I haven't quite figured out how/where to incorporate a discussion of these topics into this handbook, but
in the meantime I want to cherry-pick a few topics about probability and statistics from:
[https://eriqande.github.io/con-gen-2018/bayes-mcmc-gtyperr-narrative.nb.html](https://eriqande.github.io/con-gen-2018/bayes-mcmc-gtyperr-narrative.nb.html)


There, we will discuss _inference_ and directed acyclic graphs from the perspective of
inferring allele frequencies from genotype data.  After that discussion, we will understand that
inference is the process of learning about unobserved "parent" nodes in a DAG from the data that
has been observed in the daughter nodes of such a DAG.

Knowing that, we can go back to \@ref(fig:plated-single-geno-like) to see that making inference
about the actual alleles carried in each individual's genotype requires some sort of "prior" for
those genotypes.  Such a model is, graphically, what we were just talking about in terms of
estimating allele frequencies.  Which leads us to a full DAG for making inference about genotypes
within individuals (Figure \@ref(fig:full-geno-like-dag))
```{r full-geno-like-dag, echo=FALSE, fig.align='center', dpi=80, fig.cap='A full DAG expressing a probabilistic model for Bayesian inference of genotypes from read data.'}
knitr::include_graphics("figs/full-geno-like-dag.svg", auto_pdf = TRUE)
```

This is really how genotype inference should be done! And, it is _extremely important_ to understand that
many genotype caller provide a "called genotype" in a VCF file that _do not infer genotypes using this sort of model_.
Rather, they may often simply report the genotype with the highest _likelihood_ (but not necessarily the highest
posterior probability.)

As a consequence, especially with low coverage sequencing data, these genotypes provided by default in a VCF
will have far fewer heterozygotes than there should be.

Now we will jump to some slides from a talk I gave a couple years ago about this topic as it relates to RADseq data:
[gbs-miscall.pdf](./downloads/gbs-miscall.pdf)









# Boneyard

Standard stuff here.

Big focus on parallelizing.

