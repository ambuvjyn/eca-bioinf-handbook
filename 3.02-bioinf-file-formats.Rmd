# Bioinformatic file formats and associated tools

Almost all the high-throughput sequencing data you will deal with should
arrive in just a few different formats.  There are some specialized formats
(like those output by the program TASSEL, etc.) but we will largely ignore
those, focusing instead on the format used in production by the 1000 genomes 
and 10K vertebrate genomes projects. In a sentence, the most important are:
FASTA, FASTQ, SAM, BAM, and VCF.  

Plan: Go over these, and for each, pay special attention to compressed and indexed
forms and explain why that is so important. I think that we should probably
talk about the programs that are available for manipulating each of these, as well,
but I won't add that until we all have access to an HPC or other proper
Unix environment.



## Sequences

## FASTA 

Come back to this when we talk about alignments.

## FASTQ

The FASTQ format is the standard format for lightly-processed data
coming off an Illumina machine.  If you are doing whole genome sequencing,
it is typical for the Illumina processing pipeline to have separated all
the reads with different barcodes into different, separate files.  Typically
this means that all the reads from one library prep for one sample will
be in a single file.  The barcodes and any associated additional adapter
sequence is typically also removed from the reads. If you are processing
RAD data, the reads may not be separated by barcode, because, due to the
vagaries of the RAD library prep, the barcodes might appear on different ends
of some reads than expected.

A typical file extension for FASTQ files is `.fq`. 
Almost all FASTQ files you get from a sequencer should be gzipped to save space.
Thus, in order to view the file you will have to uncompress it.  Since you would,
in most circumstances, want to visually inspect just a few lines, it is best
to do that with `gzcat` and pipe the output to `head`.

As we have seen, paired-end sequencing produces two separate reads of a DNA
fragment.  Those two different reads are usually stored in two separate files named
in such a manner as to transparently denote whether it contains sequences obtained
from read 1 or read 2.
For example `bird_08_B03_R1.fq.gz` and `bird_08_B03_R2.fq.gz`. Read 1 and Read 2 from
a paired read must occupy the sames lines in their respective files, i.e., lines
10001-10004 in `bird_08_B03_R1.fq.gz` and lines 10001-10004 in `bird_08_B03_R2.fq.gz`
should both pertain to the same DNA fragment that was sequenced.  That is what is
meant by "paired-end" sequencing: the sequences come in pairs from different
ends of the same fragment.


The FASTQ format is _very_ simple: information about each read occupies just four lines.
This means that the number of lines in a proper FASTQ file must always be a multiple of four.
Briefly, the four lines of information about each read are always in the same order as follows:

1. An Identifier line
2. The DNA sequence as A's, C's, G's and T's.
3. A line that is almost always simply a `+` sign, but can optionally be followed
by a repeat of the ID line.
4. An ASCII-encoded, Phred-scaled base quality score.  This gives an estimated
measure of certainty about each base call in the sequence.

The code block below shows three reads worth (twelve lines) of
information from a FASTQ file.
Take a moment to identify the four different lines for each read.
```
@K00364:64:HTYYCBBXX:1:1108:4635:14133/1
TAGAATACGCCAGGTGTAAGAATAGTAGAATACGCCAGGTGTAAGAATAGTAGAACACGCCAGGTGTAAGAATAGTAGAA
+
AAAFFJJJJJFFJFJJJFJJFFJFJFJJJJJJJJFFJJJFJJJFJJAJJFJJFJJFJJJ7JJJF-<JAFJJ<F<AJAJJF
@K00364:64:HTYYCBBXX:1:1108:5081:25527/1
AAAACACCAAAAGAAAGATGCCCAGGGTCCCTGCTCATCTGCGTGAAAGTGACTTAGGCATGCTGCAAGGAGGCATGAGG
+
AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ
@K00364:64:HTYYCBBXX:1:1108:5852:47295/1
AGGTGGCTCTAGAAGGTTCTCGGACCGAGAAACAGCCTCGTACATTTGCAATGATTTCAATTCATTTTGACCATTACGAA
+
AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ
```

Lines 2 and 3 are self-explanatory, but we will expound upon lines 1 and 4 below.

### Line 1: Illumina identifier lines

The identifier line can be just about any string that starts with an `@`, but, from Illumina data, today,
you will typically see something like this:
```
@K00364:64:HTYYCBBXX:1:1108:4635:14133/1
```
The colons (and the `/`) are field separators.  The separate parts of the line
above are interpreted something along the lines as follows (keeping in mind that
Illumina occasionally changes the format and that there may be additional
optional fields):
```
@           : mandatory character that starts the ID line
K00364      : Unique sequencing machine ID 
64          : Run number on instrument
HTYYCBBXX   : Unique flow cell identifier
1           : Lane number
1108        : Tile number (section of the lane)
4635        : x-coordinate of the cluster within the tile
14133       : y-coordinate of the cluster within the tile
1           : Whether the sequence is from read 1 or read 2 
```

Question: For paired reads, do you expect the x- and y-coordinates for read 1 and read 2 to
be the same?


### Line 4: Base quality scores  

The base quality scores give an estimate of the probability that the base call is incorrect. 
This comes from data the sequencer collects on the brightness and compactness of the cluster
radiance, other factors, and Illumina's own models for base call accuracy.  If we let $p$
be the probability that a base is called incorrectly, then $Q$, the Phred-scaled base quality
score, is:

$$
Q = \lfloor-10\log_{10}p\rfloor,
$$
where $\lfloor x \rfloor$ means "the largest integer smaller than $x$.  


To get the estimate of the probability that the base is called incorrectly from
the Phred scaled score, you invert the above equation:

$$
p = \frac{1}{10^{Q/10}}
$$
Base quality scores from Illumina range from 0 to 40.
The easiest values to use as guideposts are $Q = 0, 10, 20, 30, 40$, which correspond to
error probabilites of 1, 1 in 10, 1 in 100, 1 in 1,000, and 1 in 10,000, respectively.

All this is fine and well, but when we look at the quality score line above we see
something like `7JJJF-<JAFJJ<F<AJAJJF`.  What gives?  Well, from a file storage and
parsing perspective, it makes sense to only use a single character to store the
quality score for every base.  So, that is what has been done: each of those
single characters represents a quality score---a number between 0 and 40, inclusive.

The values that have been used are the _decimal representations of ASCII text characters_ minus 33.  
The decimal representation or each character can be found in Figure \@ref(fig:ascii).
```{r ascii, echo=FALSE, fig.align='center', dpi=270, fig.cap='This lovely ASCII table shows the binary, hexadecimal, octal and decimal representations of ASCII characters (in the corners of each square; see the legend rectangle at bottom.  Table produced from TeX code written and developed by Victor Eijkhout available at [https://ctan.math.illinois.edu/info/ascii-chart/ascii.tex](https://ctan.math.illinois.edu/info/ascii-chart/ascii.tex)'}
knitr::include_graphics("figs/ascii-crop.png", auto_pdf = TRUE)
```
The decimal representation in in the upper left of each character's rectangle.  

Find the characters corresponding to base quality scores of 0, 10, 20, 30, and 40.  Remember that the
base quality score is the character's decimal representation _minus 33_.

Here is another question: why do you think the scale starts with ASCII character 33?

### A FASTQ 'tidyverse' Interlude

Here we demonstrate some R code while exploring FASTQ files.  First, in order to
do these exercises you will want to download and launch the RStudio project,
`big-fastq-play`,
that has the data
in it.  Please work within that RStudio project to do these exercises.
Here is a direct download link to it:
[https://docs.google.com/uc?export=download&id=1iD8tz_KSOHDBpXvXssqo3noPZAm1Qsjp](https://docs.google.com/uc?export=download&id=1iD8tz_KSOHDBpXvXssqo3noPZAm1Qsjp)


Note that this might stress out older laptops as it loads 100s of Mb of sequence
data into memory.

#### Reading FASTQs with `read_lines`

Load packages:
```r
library(tidyverse)

# if you don't have this package, get it
# install.packages("viridis")
library(viridis)
```

Read the FASTQ, make it a matrix, then make it a tibble

```r
# use read_lines to read the R1 fastq file line by line;
# then make a 4 column matrix, filling by rows
# then drop column 3, which corresponds to the "+" line
R1 <- read_lines("data/Battle_Creek_01_chinook_R1.fq.gz") %>%
  matrix(ncol = 4, byrow = TRUE) %>%
  .[,-3]
  

# add colnames
colnames(R1) <- c("ID", "seq", "qual")

# now make a tibble out that.  We will assign
# it back to the variable R1, to note carry
# extra memory around
R1 <- as_tibble(R1)

# Look at it:
R1


# OK, 1 million reads.
```

Look at the first ID line:
```
 @E00430:101:HKT7WCCXY:1:1101:6411:1204 1:N:0:NGATGT
```
Aha!  This is a slightly different format than the above.  The part after the
space has colon-separated fields that are:
```
1        :  which read of the pair
N        :  has this been filtered (Y/N)
0        :  control number (always 0 on HiSeq and NextSeq)
NGATGT   :  barcode on the read
```

OK, our mission is to actually look at the locations of these reads on different
tiles.  To do that we will want to access the x and y coordinates and the
tiles, etc.  In the tidyverse, this means giving each of those things its own
column.

#### tidyr::separate()

How do we break those colon-separated fields into columns?  This is a job for
`tidyr::separate` which breaks a text string on user-defined separators into
columns in a tibble.

Here we can use it to break the ID into two parts split on the space, and then
break the first part of the ID into its constituent parts:
```r
# first we break on the space,
# then we break the ID on the colons, but keep the original "id" for later
R1 %>%
  separate(ID, into = c("id", "part2"), sep = " ") %>%
  separate(
    id, 
    into = c("machine", "run", "flow_cell", "lane", "tile", "x", "y"), 
    sep = ":",
    remove = FALSE
    )
```
Wow! That was cool.  Now, your mission is to pipe that (with `%>%`)
into another `separate()` command that breaks part2 into
`read`, `filter`, `cnum`, and `barcode`, and save that into `R1_sep`

Here is a starter:
```r
R1_sep <- R1 %>%
  separate(ID, into = c("id", "part2"), sep = " ") %>%
  separate(
    id, 
    into = c("machine", "run", "flow_cell", "lane", "tile", "x", "y"), 
    sep = ":",
    remove = FALSE
    ) %>%
    ...your code here...
    
# when you are done with that, look at it
R1_sep
    
```

Doh! There is one thing to note.  Look at the first few columns of that:
```r
# A tibble: 1,000,000 x 11
   id          machine run   flow_cell lane  tile  x     y   
   <chr>       <chr>   <chr> <chr>     <chr> <chr> <chr> <chr>      
 1 @E00430:10… @E00430 101   HKT7WCCXY 1     1101  6411  1204
 2 @E00430:10… @E00430 101   HKT7WCCXY 1     1101  7324  1204
 3 @E00430:10… @E00430 101   HKT7WCCXY 1     1101  8582  1204
 4 @E00430:10… @E00430 101   HKT7WCCXY 1     1101  9841  1204
 5 @E00430:10… @E00430 101   HKT7WCCXY 1     1101  10186 1204 
```
The x- and the y-coordinates are listed as characters (`<chr>`) but they should
be numeric.  This shows the default behavior of `separate()`: it just breaks each
field into a column of strings.  However, you can ask `separate()` to make a good-faith
guess of the type of each column and convert it to that.  This works suitably in this
situation, so, let's repeat the last command, but convert types automatically:
```{r, eval=FALSE}
R1_sep <- R1 %>%
  separate(ID, into = c("id", "part2"), sep = " ") %>%
  separate(
    id, 
    into = c("machine", "run", "flow_cell", "lane", "tile", "x", "y"), 
    sep = ":",
    remove = FALSE,
    convert = TRUE
  ) %>%
  separate(part2, into = c("read", "filter", "cnum", "barcode"), sep = ":", convert = TRUE)
```

#### Counting tiles

Let's see how many tiles these reads came from.  Basically we just want to count the
number of rows with different values for tile.  Read the documentation for
`dplyr::count` with 
```r
?count
```
and when you are done count up the number of reads in each tile:
```r
R1_sep %>%
  ...your code here...
```

Turns out they are all from the same tile...

#### Parsing quality scores

Now, we want to turn the quality-score ASCII-characters into Phred-scaled
qualities, ultimately taking the average over each sequence of those.

Check out this function:
```{r}
utf8ToInt("!*JGH")
```
We can use that to get Phred-scaled values by subtracting 33 from the result.  Let's check:
```{r}
utf8ToInt("!+5?IJ") - 33
```
Note that `J` seems to be used for "below 1 in 10,000" as it is the highest I have ever seen.

So, what we want to do is make a new column called `mean_qual` that gives the
mean of the Phred-scaled qualities.  Any time you need to make a new column in a
tibble, where the result in each row depends only on the values in current columns
in that same row, that is a job for `mutate()`.

However, in this case, because the `utf8ToInt()` function doesn't take vector input,
computing the `mean_qual` for every row requres using one of the `map()` family of functions.
It is a little beyond
what we want to delve into at the moment. But here is what it looks like:
```{r, eval=FALSE}
R1_sepq <- R1_sep %>%
  mutate(mean_qual = map_dbl(.x = qual, .f = function(x) mean(utf8ToInt(x) - 33))
```

Check out the distribution of those mean quality scores:
```r
ggplot(R1_sepq, aes(x = mean_qual)) +
  geom_histogram(binwidth = 1)
```

#### Investigating the spatial distribution of reads and quality scores

Now, use the above as a template to investigate the distribution of the
x-values:
```r
ggplot(R1_sepq, aes(...your code here...)) +
  geom_histogram(bins = 500)
```

And, do the same for the y-values.   
```r
# Dsn of y
ggplot(R1_sepq, aes(x = y)) +
  geom_histogram(bins = 500) +
  coord_flip()
```


Hmm... for fun, make a 2-D hex-bin plot
```r
ggplot(R1_sepq, aes(x = x, y = y)) +
  geom_hex(bins = 100) +
  scale_fill_viridis_c()
```

That is super interesting.  It looks like the flowcell or camera must have a mild
issue where the smears are between y = 20,000 and 30,000.

It is natural to wonder if the quality scores of the reads that did actually get
recovered from those regions have lower quality scores.  This makes a hexbin plot 
of the mean quality scores:
```r
# hexbin of the mean quality score
ggplot(R1_sepq, aes(x = x, y = y, z = mean_qual)) +
  stat_summary_hex(bins = 100) +
  scale_fill_viridis_c()
```

Cool.

### Comparing read 1 to read 2

One question that came up in class is whether the quality of read 2 is typically lower
than that of read 1.  We can totally answer that with the data we have. It would involve,

1. reading in all the read 2 reads and separating columns.
2. computing the read 2 mean quality scores
3. joining (see `left_join()`) on the `id` columns and then making a scatter plot.

Go for it...




## Alignments

SAM/BAM.  Talk about them being sorted or not.  Note that the headers between these
and VCF are similar. 

Have a discussion here about naming positions within the genome
and talk about 0-based vs 1-based coordinates.

### Samtools {#samtools}


## Variants

In terms of the format/standard, is going to be well worth explaining the early
part of section 5 of the standard so that people know how insertions and deletions 
are coded.  I hadn't really digested that until just today.  Basically, the position
in the VCF file correponds to the first character in either the REF or the ALT field.  
When you remember that, it all falls into place.

VCF.  I've mostly used vcftools until now, but I've gotta admit that the interface
is awful with all the --recode BS.  Also, it is viciously slow.  So, let's just 
skip it all together and learn how to use bcftools.  One nice thing about 
bcftools is that it works a whole lot like samtools, syntactically.  

Note that for a lot of the commands you need to have an indexed vcf.gz.


## Segments

BED

## Conversion/Extractions between different formats

* vcflib's vcf2fasta takes a phased VCF file and a fasta file and spits out sequence.  